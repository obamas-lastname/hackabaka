{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94901157",
   "metadata": {},
   "source": [
    "\n",
    "# 🛡️ SentinelPOS — AI/ML SIEM for Real‑Time POS Fraud\n",
    "\n",
    "This notebook is a **professional demo** of the project built for the ESTEEC Olympics Hackathon.\n",
    "\n",
    "**What you'll see:**\n",
    "- Architecture overview of our **end-to-end SIEM**\n",
    "- Load & explore a small sample of the POS dataset\n",
    "- **History-aware feature engineering** (velocity, distance, novelty)\n",
    "- Model **training & evaluation** (80/20 split)\n",
    "- **Precision–Recall** curve and **threshold selection**\n",
    "- Save artifacts for the real-time API: `model.pkl`, `features.json`, `threshold.json`\n",
    "- (Optional) **Live prediction** call to our FastAPI endpoint\n",
    "\n",
    "> Tip: For a smooth live run, keep the dataset sample around **50,000 rows** (or less). Train the full model offline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e50ef",
   "metadata": {},
   "source": [
    "\n",
    "## 🧩 System Architecture\n",
    "\n",
    "```\n",
    "           ┌────────────────────────────┐\n",
    "           │  Hackathon Stream (SSE)    │\n",
    "           └────────────┬───────────────┘\n",
    "                        │ events\n",
    "                        ▼\n",
    "               sse_to_predict.py\n",
    "        ┌───────────────┼────────────────┐\n",
    "        │               │                │\n",
    "        ▼               ▼                ▼\n",
    " FastAPI /predict   /api/flag (judge)   Next.js /api/stream\n",
    "   (SQLite + ML)     ← response rate      (SSE dashboard)\n",
    "        │\n",
    "        ▼\n",
    "  model.pkl + features.json + threshold.json\n",
    "```\n",
    "\n",
    "- **Collector:** `sse_to_predict.py`\n",
    "- **Analyzer:** FastAPI + scikit-learn model\n",
    "- **Feature Store:** SQLite (user history → behavioral features)\n",
    "- **Alerting:** POST to `/api/flag` with decision within 30s\n",
    "- **Visualization:** Next.js SSE dashboard (live alerts & charts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73384c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Imports & configuration\n",
    "import os, json, math, sqlite3, statistics, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             precision_recall_curve, average_precision_score,\n",
    "                             roc_auc_score)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\", \"../hackathon_train.csv\")   # pipe-delimited dataset\n",
    "MODEL_PATH = \"model.pkl\"\n",
    "FEATURES_PATH = \"features.json\"\n",
    "THRESHOLD_PATH = \"threshold.json\"\n",
    "\n",
    "NB_DEMO_ROWS = int(os.getenv(\"NB_DEMO_ROWS\", \"50000\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c5f84",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load a Sample of the Dataset\n",
    "\n",
    "We load a manageable slice and **sort by `unix_time`** to preserve causality (features only use past).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5269c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows loaded: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssn</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>merchant</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>transaction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576-07-9241</td>\n",
       "      <td>180059854173232</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Moore</td>\n",
       "      <td>M</td>\n",
       "      <td>86175 Barnes Circles</td>\n",
       "      <td>Lake Wales</td>\n",
       "      <td>FL</td>\n",
       "      <td>33898</td>\n",
       "      <td>27.8643</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1758834000</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>39.64</td>\n",
       "      <td>0</td>\n",
       "      <td>fraud_Reilly, Heaney and Cole</td>\n",
       "      <td>28.548351</td>\n",
       "      <td>-81.596743</td>\n",
       "      <td>d9e602e3-a45d-45d1-bad2-c1534ed6c4f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727-46-9662</td>\n",
       "      <td>347151813192013</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>5073 Gill Dale</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>CA</td>\n",
       "      <td>90501</td>\n",
       "      <td>33.8268</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>1758834001</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>65.55</td>\n",
       "      <td>0</td>\n",
       "      <td>fraud_Zieme, Bode and Dooley</td>\n",
       "      <td>34.241997</td>\n",
       "      <td>-118.355662</td>\n",
       "      <td>0eb36227-59d1-435b-a446-c3d4dde749ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>684-83-0896</td>\n",
       "      <td>375537948969934</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Patton</td>\n",
       "      <td>M</td>\n",
       "      <td>68081 Ferrell Station</td>\n",
       "      <td>Chaparral</td>\n",
       "      <td>NM</td>\n",
       "      <td>88081</td>\n",
       "      <td>32.2239</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>1758834001</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>34.12</td>\n",
       "      <td>0</td>\n",
       "      <td>fraud_Greenholt, Jacobi and Gleason</td>\n",
       "      <td>33.189298</td>\n",
       "      <td>-105.553728</td>\n",
       "      <td>32a08dd2-f4aa-43df-98fa-aa964f267160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ssn           cc_num        first      last gender  \\\n",
       "0  576-07-9241  180059854173232       Edward     Moore      M   \n",
       "1  727-46-9662  347151813192013  Christopher  Williams      M   \n",
       "2  684-83-0896  375537948969934        Aaron    Patton      M   \n",
       "\n",
       "                  street        city state    zip      lat  ...  trans_date  \\\n",
       "0   86175 Barnes Circles  Lake Wales    FL  33898  27.8643  ...  2025-09-26   \n",
       "1         5073 Gill Dale    Torrance    CA  90501  33.8268  ...  2025-09-26   \n",
       "2  68081 Ferrell Station   Chaparral    NM  88081  32.2239  ...  2025-09-26   \n",
       "\n",
       "   trans_time   unix_time       category    amt is_fraud  \\\n",
       "0    00:00:00  1758834000  gas_transport  39.64        0   \n",
       "1    00:00:01  1758834001  gas_transport  65.55        0   \n",
       "2    00:00:01  1758834001  gas_transport  34.12        0   \n",
       "\n",
       "                              merchant  merch_lat  merch_long  \\\n",
       "0        fraud_Reilly, Heaney and Cole  28.548351  -81.596743   \n",
       "1         fraud_Zieme, Bode and Dooley  34.241997 -118.355662   \n",
       "2  fraud_Greenholt, Jacobi and Gleason  33.189298 -105.553728   \n",
       "\n",
       "                         transaction_id  \n",
       "0  d9e602e3-a45d-45d1-bad2-c1534ed6c4f6  \n",
       "1  0eb36227-59d1-435b-a446-c3d4dde749ca  \n",
       "2  32a08dd2-f4aa-43df-98fa-aa964f267160  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %% Load sample\n",
    "df = pd.read_csv(DATA_PATH, sep=\"|\", nrows=NB_DEMO_ROWS)\n",
    "\n",
    "for col in [\"amt\",\"lat\",\"long\",\"merch_lat\",\"merch_long\",\"city_pop\",\"unix_time\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "if \"unix_time\" in df.columns:\n",
    "    df = df.sort_values(\"unix_time\").reset_index(drop=True)\n",
    "\n",
    "print(\"Rows loaded:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647a1c6",
   "metadata": {},
   "source": [
    "\n",
    "## 2) History‑Aware Feature Engineering\n",
    "\n",
    "We compute features that reflect **user behavior and context**:\n",
    "- **Velocity**: transactions in the last 60s / 5m / 15m / 1h\n",
    "- **Uniqueness**: unique merchants & categories in last 15m\n",
    "- **Novelty**: seen merchant before?\n",
    "- **Temporal**: hour, day of week, night flag\n",
    "- **Distances**: previous merchant → current merchant, user → merchant\n",
    "- **User profile**: mean/std spend in last 24h, z‑score of current amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Feature engineering helpers\n",
    "def fast_age(dob_str, at_unix):\n",
    "    try:\n",
    "        y, m, d = map(int, str(dob_str)[:10].split(\"-\"))\n",
    "        t = dt.datetime.utcfromtimestamp(int(at_unix))\n",
    "        return max(0, t.year - y - ((t.month, t.day) < (m, d)))\n",
    "    except Exception:\n",
    "        return -1\n",
    "\n",
    "def hour_from_unix(u):\n",
    "    try:\n",
    "        return dt.datetime.utcfromtimestamp(int(u)).hour\n",
    "    except Exception:\n",
    "        return -1\n",
    "\n",
    "def dow_from_unix(u):\n",
    "    try:\n",
    "        return dt.datetime.utcfromtimestamp(int(u)).weekday()\n",
    "    except Exception:\n",
    "        return -1\n",
    "\n",
    "def is_night(h):\n",
    "    return 1 if (h <= 6 or h >= 22) else 0\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        R = 6371.0\n",
    "        phi1 = math.radians(float(lat1)); phi2 = math.radians(float(lat2))\n",
    "        dphi = math.radians(float(lat2) - float(lat1))\n",
    "        dlmb = math.radians(float(lon2) - float(lon1))\n",
    "        a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlmb/2)**2\n",
    "        return 2 * R * math.asin(math.sqrt(a))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def add_base_columns(df):\n",
    "    df = df.copy()\n",
    "    df[\"age\"] = [fast_age(d, u) for d, u in zip(df.get(\"dob\", \"\"), df[\"unix_time\"])]\n",
    "    df[\"hour\"] = [hour_from_unix(u) for u in df[\"unix_time\"]]\n",
    "    df[\"dow\"] = [dow_from_unix(u) for u in df[\"unix_time\"]]\n",
    "    df[\"is_night\"] = df[\"hour\"].apply(is_night)\n",
    "    df[\"log_amt\"] = np.log1p(df[\"amt\"].fillna(0.0))\n",
    "    for col in [\"lat\",\"long\",\"merch_lat\",\"merch_long\",\"city_pop\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "    g = df.get(\"gender\",\"\").astype(str).str.upper()\n",
    "    df[\"gender_M\"] = (g == \"M\").astype(int)\n",
    "    df[\"gender_F\"] = (g == \"F\").astype(int)\n",
    "    return df\n",
    "\n",
    "def add_history_features(df):\n",
    "    df = df.copy()\n",
    "    cols = [\"velocity_60s\",\"velocity_5m\",\"velocity_15m\",\"velocity_1h\",\n",
    "            \"unique_merchants_15m\",\"unique_categories_15m\",\n",
    "            \"seen_merchant_before\",\"user_merchant_dist_km\",\n",
    "            \"time_since_last_s\",\"time_since_last_merchant_s\",\n",
    "            \"user_mean_amt_24h\",\"user_std_amt_24h\",\"user_amt_delta\",\"amt_z_user\"]\n",
    "    for c in cols: df[c] = 0.0\n",
    "\n",
    "    for cc, g in df.groupby(\"cc_num\", sort=False):\n",
    "        idx = g.index.values\n",
    "        times = g[\"unix_time\"].values.astype(np.int64)\n",
    "        amts = g[\"amt\"].fillna(0.0).values.astype(float)\n",
    "        merch = g[\"merchant\"].astype(str).values\n",
    "\n",
    "        lat_u = g[\"lat\"].values; lon_u = g[\"long\"].values\n",
    "        lat_m = g[\"merch_lat\"].values; lon_m = g[\"merch_long\"].values\n",
    "\n",
    "        start = 0\n",
    "        for i in range(len(g)):\n",
    "            t = times[i]\n",
    "            while start < i and times[start] < t - 24*3600:\n",
    "                start += 1\n",
    "            past = slice(start, i)\n",
    "\n",
    "            v60  = np.sum(times[past] >= t - 60)\n",
    "            v5   = np.sum(times[past] >= t - 5*60)\n",
    "            v15  = np.sum(times[past] >= t - 15*60)\n",
    "            v1h  = np.sum(times[past] >= t - 60*60)\n",
    "\n",
    "            mask15 = times[past] >= t - 15*60\n",
    "            uniq_merch = len(set(merch[past][mask15]))\n",
    "            uniq_cat   = len(set(g[\"category\"].astype(str).values[past][mask15]))\n",
    "\n",
    "            seen_before = 1 if (merch[i] in set(merch[past])) else 0\n",
    "\n",
    "            tsl = (t - times[i-1]) if i > 0 else 10**9\n",
    "\n",
    "            prev_same = None\n",
    "            for j in range(i-1, start-1, -1):\n",
    "                if merch[j] == merch[i]:\n",
    "                    prev_same = times[j]; break\n",
    "            tslm = (t - prev_same) if prev_same is not None else 10**9\n",
    "\n",
    "            if i > 0:\n",
    "                mlat_prev = lat_m[i-1] if not np.isnan(lat_m[i-1]) else lat_u[i-1]\n",
    "                mlon_prev = lon_m[i-1] if not np.isnan(lon_m[i-1]) else lon_u[i-1]\n",
    "                dist_prev_to_now = haversine_km(mlat_prev, mlon_prev,\n",
    "                                                lat_m[i] if not np.isnan(lat_m[i]) else lat_u[i],\n",
    "                                                lon_m[i] if not np.isnan(lon_m[i]) else lon_u[i])\n",
    "            else:\n",
    "                dist_prev_to_now = 0.0\n",
    "\n",
    "            dist_user_to_merchant = haversine_km(lat_u[i], lon_u[i], lat_m[i], lon_m[i])\n",
    "            if np.isnan(dist_user_to_merchant): dist_user_to_merchant = 0.0\n",
    "\n",
    "            past_amts = amts[past]\n",
    "            if past_amts.size:\n",
    "                mean24 = float(past_amts.mean())\n",
    "                std24  = float(past_amts.std(ddof=0))\n",
    "            else:\n",
    "                mean24, std24 = 0.0, 0.0\n",
    "            delta = float(amts[i] - mean24)\n",
    "            z = float(delta / std24) if std24 > 0 else 0.0\n",
    "\n",
    "            df.loc[idx[i], [\"velocity_60s\",\"velocity_5m\",\"velocity_15m\",\"velocity_1h\"]] = [v60, v5, v15, v1h]\n",
    "            df.loc[idx[i], [\"unique_merchants_15m\",\"unique_categories_15m\"]] = [uniq_merch, uniq_cat]\n",
    "            df.loc[idx[i], \"seen_merchant_before\"] = float(seen_before)\n",
    "            df.loc[idx[i], \"user_merchant_dist_km\"] = float(0.0 if np.isnan(dist_prev_to_now) else dist_prev_to_now)\n",
    "            df.loc[idx[i], \"time_since_last_s\"] = float(tsl)\n",
    "            df.loc[idx[i], \"time_since_last_merchant_s\"] = float(tslm)\n",
    "            df.loc[idx[i], [\"user_mean_amt_24h\",\"user_std_amt_24h\",\"user_amt_delta\",\"amt_z_user\"]] = [mean24, std24, delta, z]\n",
    "    return df\n",
    "\n",
    "FEATURE_ORDER = [\n",
    "    \"age\",\"log_amt\",\"hour\",\"dow\",\"is_night\",\n",
    "    \"city_pop\",\"lat\",\"long\",\"merch_lat\",\"merch_long\",\n",
    "    \"velocity_60s\",\"velocity_5m\",\"velocity_15m\",\"velocity_1h\",\n",
    "    \"unique_merchants_15m\",\"unique_categories_15m\",\n",
    "    \"seen_merchant_before\",\"user_merchant_dist_km\",\n",
    "    \"time_since_last_s\",\"time_since_last_merchant_s\",\n",
    "    \"user_mean_amt_24h\",\"user_std_amt_24h\",\"user_amt_delta\",\"amt_z_user\",\n",
    "    \"gender_M\",\"gender_F\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9bee9",
   "metadata": {},
   "source": [
    "\n",
    "### Build the feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d334c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Build features\n",
    "base = add_base_columns(df)\n",
    "feat_df = add_history_features(base)\n",
    "\n",
    "if \"is_fraud\" not in feat_df.columns:\n",
    "    raise ValueError(\"Column 'is_fraud' is required in the dataset.\")\n",
    "\n",
    "y = feat_df[\"is_fraud\"].astype(str).str.lower().map(\n",
    "    {\"1\":1,\"0\":0,\"true\":1,\"false\":0,\"t\":1,\"f\":0,\"yes\":1,\"no\":0}\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "X = feat_df[FEATURE_ORDER].fillna(0.0).astype(float).values\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fee1f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Train / Evaluate (80/20 split)\n",
    "We bias toward **recall** using class weights (fraud is rare).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Split & train\n",
    "strat = y if (y.sum() and y.sum() != len(y)) else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=strat\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=160,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight={0:1.0, 1:5.0}\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "y_pred_50 = (y_prob >= 0.50).astype(int)\n",
    "\n",
    "print(\"=== Metrics @ 0.50 threshold ===\")\n",
    "print(classification_report(y_test, y_pred_50, digits=4))\n",
    "print(\"Confusion matrix @ 0.50:\")\n",
    "print(confusion_matrix(y_test, y_pred_50))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob))\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_prob)\n",
    "f1 = (2*prec*rec) / (prec + rec + 1e-12)\n",
    "best_idx = int(np.argmax(f1))\n",
    "best_thr = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "print(f\"Suggested threshold (max F1): {best_thr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3341c",
   "metadata": {},
   "source": [
    "\n",
    "### Precision–Recall curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Plot PR curve\n",
    "plt.figure()\n",
    "plt.plot(rec, prec, linewidth=2)\n",
    "if 0 <= best_idx < len(rec):\n",
    "    plt.scatter(rec[best_idx], prec[best_idx], s=40)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24245f0",
   "metadata": {},
   "source": [
    "\n",
    "### Metrics at the suggested threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Evaluate at best threshold\n",
    "y_pred_best = (y_prob >= best_thr).astype(int)\n",
    "print(\"=== Metrics @ best threshold ===\")\n",
    "print(classification_report(y_test, y_pred_best, digits=4))\n",
    "print(\"Confusion matrix @ best threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff242de",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Save Artifacts (for API + Streamer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b96e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Save model + features + threshold\n",
    "import joblib, json\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "with open(FEATURES_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(FEATURE_ORDER, f, indent=2)\n",
    "with open(THRESHOLD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"threshold\": float(best_thr)}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", MODEL_PATH, FEATURES_PATH, THRESHOLD_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4400ef",
   "metadata": {},
   "source": [
    "\n",
    "## 5) (Optional) Live Predict via FastAPI\n",
    "\n",
    "Start your API in a terminal:\n",
    "\n",
    "```bash\n",
    "uvicorn fraud_api:app --host 127.0.0.1 --port 8000\n",
    "```\n",
    "\n",
    "Then run this cell to score a sample transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Live predict demo (optional)\n",
    "import requests\n",
    "\n",
    "FASTAPI_URL = os.getenv(\"FASTAPI_URL\", \"http://127.0.0.1:8000/predict?store=0\")\n",
    "\n",
    "try:\n",
    "    sample_tx = df.iloc[len(df)//2].to_dict()\n",
    "    r = requests.post(FASTAPI_URL, json=sample_tx, timeout=5)\n",
    "    print(\"HTTP\", r.status_code)\n",
    "    print(r.text[:600])\n",
    "    try:\n",
    "        print(json.dumps(r.json(), indent=2))\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print(\"Live predict skipped or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d454a08",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Feature Importance (Explainability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Plot top feature importances\n",
    "import numpy as np\n",
    "\n",
    "importances = model.feature_importances_\n",
    "order = np.argsort(importances)[::-1][:15]\n",
    "names = [FEATURE_ORDER[i] for i in order]\n",
    "vals = importances[order]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(len(vals)), vals)\n",
    "plt.xticks(range(len(vals)), names, rotation=45, ha=\"right\")\n",
    "plt.title(\"Top Feature Importances (RandomForest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8a2bf",
   "metadata": {},
   "source": [
    "\n",
    "## 🏁 Conclusion\n",
    "\n",
    "- **Training:** uses history-aware signals (velocity, novelty, distance, temporal) to predict fraud.\n",
    "- **Thresholding:** selects an operating point from the **Precision–Recall** curve to balance recall vs precision.\n",
    "- **Artifacts:** saved to disk so the FastAPI + streamer can operate in real time.\n",
    "- **Dashboard:** Next.js SSE shows live alerts and trends during the hackathon.\n",
    "\n",
    "**Next ideas**\n",
    "- Add anomaly scores (e.g., IsolationForest)\n",
    "- Geo heatmap view of frauds\n",
    "- Nightly re-training job with fresh labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
